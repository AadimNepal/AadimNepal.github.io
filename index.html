<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Aadim Nepal</title>
  <meta name="author" content="Aadim Nepal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Aadim Nepal - AI Researcher at NYU Abu Dhabi">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ§ </text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- ==================== BIO SECTION ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Aadim Nepal
                  </p>
                  <p>
                    I am a senior undergraduate studying Mathematics and Computer Science at <a href="https://nyuad.nyu.edu/">NYU Abu Dhabi</a>, where I work with Professor <a href="https://scholar.google.com/citations?user=PKlLfooAAAAJ">Keith Ross</a> on energy-based world models.
                  </p>
                  <p>
                    I am broadly interested in planning, JEPA, self-supervised learning, and understanding how large language models reason. My research focuses on understanding the mechanisms behind LLM reasoning, including how reinforcement learning and distillation shape reasoning behavior, and how layer-level structure supports mathematical reasoning.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:an4036@nyu.edu">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?hl=en&user=VNrmCEIAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/AadimNepal">GitHub</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/aadim-nepal-770561187/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/aadim.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/aadim.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- ==================== RESEARCH SECTION ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in understanding and improving reasoning in large language models, self-supervised learning, and energy-based models. My work spans LLM reasoning mechanisms, model compression, and multimodal learning.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- ==================== PAPER 1 ==================== -->
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2602.01997">
                    <span class="papertitle">On the Limits of Layer Pruning for Generative Reasoning in LLMs</span>
                  </a>
                  <br>
                  Safal Shrestha, Anubhav Shrestha, <strong>Aadim Nepal</strong>, Minwu Kim, Keith Ross
                  <br>
                  <em>arXiv</em>, 2026
                  <br>
                  <a href="https://arxiv.org/abs/2602.01997">arXiv</a>
                  <p></p>
                </td>
              </tr>

              <!-- ==================== PAPER 2 ==================== -->
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2506.22638">
                    <span class="papertitle">Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training</span>
                  </a>
                  <br>
                  <strong>Aadim Nepal</strong>, Safal Shrestha, Anubhav Shrestha, Minwu Kim, Jalal Naghiyev, Ravid Shwartz-Ziv, Keith Ross
                  <br>
                  <em>The 5th Workshop on Mathematical Reasoning and AI at NeurIPS</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2506.22638">arXiv</a>
                  <p></p>
                  <p>Math reasoning depends on a few critical layers that form during pre-training and remain stable across all post-training methods. Removing these layers reduces math accuracy by up to 80%.</p>
                </td>
              </tr>

              <!-- ==================== PAPER 3 ==================== -->
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.14216">
                    <span class="papertitle">Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning</span>
                  </a>
                  <br>
                  Minwu Kim, Anubhav Shrestha, Safal Shrestha, <strong>Aadim Nepal</strong>, Keith Ross
                  <br>
                  <em>The 5th Workshop on Mathematical Reasoning and AI at NeurIPS</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2505.14216">arXiv</a>
                  <p></p>
                  <p>RLVR improves accuracy on easier questions but struggles with capability, while distillation can improve both&mdash;but only when new knowledge is introduced.</p>
                </td>
              </tr>

              <!-- ==================== PAPER 4 ==================== -->
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.13718">
                    <span class="papertitle">Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings</span>
                  </a>
                  <br>
                  Safal Shrestha, Minwu Kim, <strong>Aadim Nepal</strong>, Anubhav Shrestha, Keith Ross
                  <br>
                  <em>EMNLP</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2505.13718">arXiv</a>
                  <p></p>
                  <p>A two-stage training strategy that warms up with simple logic puzzles before applying RLVR, enabling sample-efficient reasoning under limited supervision.</p>
                </td>
              </tr>

              <!-- ==================== PAPER 5 ==================== -->
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data</span>
                  <br>
                  S. Shurrab, <strong>Aadim Nepal</strong>, TJ John, NG Ghazi, B Piechowski-Jozwiak, ...
                  <br>
                  <em>EMBC Main</em>, 2025
                  <p></p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- ==================== FOOTER ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Website template from <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>
