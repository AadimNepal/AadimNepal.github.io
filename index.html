<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Aadim Nepal</title>
  <meta name="author" content="Aadim Nepal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Aadim Nepal - AI Researcher at NYU Abu Dhabi">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ§ </text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- ==================== BIO SECTION ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Aadim Nepal
                  </p>
                  <p>
                    I am a senior undergraduate studying Mathematics and Computer Science at <a href="https://nyuad.nyu.edu/">NYU Abu Dhabi</a>, where I work with Professor <a href="https://scholar.google.com/citations?user=RhUcYmQAAAAJ&hl=en">Keith Ross</a> on energy-based world models.
                  </p>
                  <p>
                    
                    Previously, I worked on LLM reasoning and interpretability. Currently, I focus on how to get systems to learn from the physical world. I am interested in how principles from neuroscience and biology can inform the design of models that plan, predict, and generalize the way biological systems do.
                  <p style="text-align:center">
                    <a href="mailto:an3854@nyu.edu">Email</a> &nbsp;/&nbsp;
                    <a href="data/AadimNepal-CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="data/AadimNepal-bio.txt">Bio</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?hl=en&user=VNrmCEIAAAAJ">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://x.com/NepalAadim">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://github.com/AadimNepal">GitHub</a> &nbsp;/&nbsp;
                    <a href="miscellaneous.html">Miscellaneous</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <!-- <a href="images/aadim.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/aadim.jpg" class="hoverZoomLink"></a> -->
                   <a href="images/aadim.jpg"><img style="width:250px;height:250px;object-fit:cover;object-position:75% 20%;border-radius:50%;" alt="profile photo" src="images/aadim.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- ==================== RESEARCH HEADING ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I am interested in using model-based RL for System 2 planning. I study how systems can learn physical dynamics through self-supervised learning and world models. Much of my past work is in LLM reasoning and interpretability, but I am now focused on the foundational question of how to build human-level AI. Representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- ==================== PAPERS ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- ===== PAPER 1: On the Limits of Layer Pruning ===== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src="images/layer_pruning.png" width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2602.01997">
                    <span class="papertitle">On the Limits of Layer Pruning for Generative Reasoning in LLMs</span>
                  </a>
                  <br>
                  Safal Shrestha, Anubhav Shrestha, <strong>Aadim Nepal</strong>, Minwu Kim, Keith Ross
                  <br>
                  <em>arXiv</em>, 2026
                  <br>
                  <a href="https://arxiv.org/abs/2602.01997">arXiv</a>
                  <p></p>
                  <p>Investigates the fundamental limits of layer pruning for maintaining generative reasoning capabilities in large language models.</p>
                </td>
              </tr>

              <!-- ===== PAPER 2: Layer Importance (HIGHLIGHTED) ===== -->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src="images/layer_importance.png" width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2506.22638">
                    <span class="papertitle">Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training</span>
                  </a>
                  <br>
                  <strong>Aadim Nepal</strong>, Safal Shrestha, Anubhav Shrestha, Minwu Kim, Jalal Naghiyev, Ravid Shwartz-Ziv, Keith Ross
                  <br>
                  <em>The 5th Workshop on Mathematical Reasoning and AI at NeurIPS</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2506.22638">arXiv</a>
                  <p></p>
                  <p>Math reasoning depends on a few critical layers that form during pre-training and remain stable across all post-training methods. Removing these layers reduces math accuracy by up to 80%, while factual recall shows smaller drops.</p>
                </td>
              </tr>

              <!-- ===== PAPER 3: RL vs Distillation ===== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src="images/rl_vs_distill.png" width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.14216">
                    <span class="papertitle">Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning</span>
                  </a>
                  <br>
                  Minwu Kim, Anubhav Shrestha, Safal Shrestha, <strong>Aadim Nepal</strong>, Keith Ross
                  <br>
                  <em>The 5th Workshop on Mathematical Reasoning and AI at NeurIPS</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2505.14216">arXiv</a>
                  <p></p>
                  <p>RLVR improves accuracy on easier questions but struggles with capability, while distillation can improve both&mdash;but only when new knowledge is introduced.</p>
                </td>
              </tr>

              <!-- ===== PAPER 4: Warm Up Before You Train ===== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src="images/warmup.png" width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.13718">
                    <span class="papertitle">Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings</span>
                  </a>
                  <br>
                  Safal Shrestha, Minwu Kim, <strong>Aadim Nepal</strong>, Anubhav Shrestha, Keith Ross
                  <br>
                  <em>EMNLP</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2505.13718">arXiv</a>
                  <p></p>
                  <p>A two-stage training strategy that warms up with simple logic puzzles before applying RLVR, enabling sample-efficient reasoning under limited supervision.</p>
                </td>
              </tr>

              <!-- ===== PAPER 5: Multimodal Stroke ===== -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src="images/stroke.png" width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.02677">
                    <span class="papertitle">Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data</span>
                  </a>
                  <br>
                  Saeed Shurrab, <strong>Aadim Nepal</strong>, Terrence J. Lee-St. John, Nicola G. Ghazi, Bart Piechowski-Jozwiak, Farah Shamout
                  <br>
                  <em>EMBC</em>, 2025
                  <br>
                  <a href="https://arxiv.org/abs/2505.02677">arXiv</a>
                  <p></p>
                  <p>A multimodal deep neural network combining OCT and infrared retinal scans with clinical data for stroke prediction, achieving 5% AUROC improvement over image-only baselines and 8% over existing foundation models.</p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- ==================== FOOTER ==================== -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                   <p style="text-align:center;font-size:small;">
                    Website template from <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
  </table>
</body>
</html>